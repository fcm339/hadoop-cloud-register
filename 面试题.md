学习网站：
    
    https://time.geekbang.org/column/article/364761

日志打印的级别有多少种，每种有啥不同

![image-20210609215206870](https://i.loli.net/2021/06/09/O27NcdLZSGAi5yW.png)

| 日志级别   | 描述                                         |
| ---------- | -------------------------------------------- |
| ALL 所有   | 所有日志级别，包括定制级别                   |
| TRACE 跟踪 | 指明程序运行轨迹，比DEBUG级别的粒度更细      |
| DEBUG 调试 | 指明细致的事件信息，对调试应用最有用         |
| INFO 信息  | 指明描述信息，从粗粒度上描述了应用运行过程   |
| WARN 警告  | 指明可能潜在的危险状况                       |
| ERROR 错误 | 指明错误事件，但应用可能还能继续运行         |
| FATAL 致命 | 指明非常严重的可能会导致应用终止执行错误事件 |
| OFF 关闭   | 最高级别，不打印日志                         |



2. 修改一个数据库的字段语句

   
类加载和类加载的过程

jdk1.7为什么把字符串常量池和静态常量池放到堆中。

jvm哪些地方会oom和gc。哪些不会

    虚拟机栈，方法区，堆内存，元空间 只要jvm个区域没有办法申请内存空间来存储新进入的对象。
    程序技术器不会
synhronized和reenrantlock的区别
   
常用的jvm参数

4. mybatis的分页方式有多少种 [参考](https://blog.csdn.net/qq_39052513/article/details/108056713) 
   - 将所有数据查出来，通过  List 的 `subList(startIndex, endIndex)` 来分页
   - 使用 `LIMIT` 关键字分页
   - `RowBounds` 分页：`empMapper.selectAll(new RowBounds(start, limit))` 
   - 自定义拦截器分页，实现复杂，`PageHelper` 工具类实际上就是一个拦截器



5. springboot的配置文件

   - 配置文件的作用：修改SpringBoot自动配置的默认值

   - 字符串不用加引号，加单引号则将特殊字符转成字符串，加双引号会转义成对应的含义，如`"\n"` 会换行，而 `'\n'` 就只是表示 `'\n'` 

   - 配置文件值注入：`@ConfigurationProperties(prefix = "...") `


面向对象的设计原则:
  
    
面向对象编程的三大特性：
    
    封装：通过public private protected，final，static等方式来控制类中方法变量的访问权限和是否可继承重写
    
    继承：
    
    多态：
    

多态：
    
    https://www.cnblogs.com/chenssy/p/3372798.html

    什么是多态：
    
        相同的消息使得不同的类做出不同的响应
        
    如何实现多态：
         通过继承父类，重写父类方法，向上引用（子类对象指向父类）
    

---
final关键字的作用
    
    https://www.cnblogs.com/coderD/p/13823805.html
    
    final可以修饰类，方式，变量
    
    修饰类：表示不能被继承，该类中的成员方法也被隐式的修饰为final
    
    修饰方法：表示方法不能被重写
    
    修饰变量：修饰的变量在第一次赋值后不可修改，修饰基础类型，值初始化后不会改变。修饰引用类型也就是对象，该变量存储类对象的引用地址，不可以修改。对象本身的操作不受影响
    
   
    
----------------------static-------------------------------------------

    https://www.cnblogs.com/swisszhang/p/9892992.html
    https://www.cnblogs.com/lh-cml/archive/2019/07/12/11176930.html
    https://www.cnblogs.com/bichen-01/p/11198753.html
    static关键字，可以修饰类，方法，变量，静态块
    
    静态方法和变量，类加载的时候初始化的，属于类，在类实例之间共享的，全局唯一。
    
    静态块里面的代码只执行一次，且只在初始化类的时候执行
    
    用static修饰的内部类，称为静态内部类，完全属于外部类本身，不属于外部类某一个对象
    
    静态内部类可以包含静态成员，也可以包含非静态成员，但是在非静态内部类中不可以声明静态成
     
    静态类内部不可以访问外部类的实例成员，只能访问外部类的类成员
     
    静态资源的加载顺序是严格按照静态资源的定义顺序来加载的
    
    静态代码块是严格按照父类静态代码块->子类静态代码块的顺序加载的，且只加载一次。
    
为什么要用内部类，说一下成员内部类，静态内部类，局部内部类，匿名内部类

    https://blog.csdn.net/weixin_43647393/article/details/103244586   
    https://blog.csdn.net/green703338130/article/details/81053980?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control

静态方法和静态属性能不能被继承重写
    
    静态方法和静态属性能被继承，但是不能被重写。如果子类中有和父类方法名，参数类型数量都用一样，返回类型也要一样的方法，该子类实际上只是将父类中的该同名方法进行了隐藏，而非重写
    如果加上@Override会报错
    重写指的是根据运行时对象的类型来决定调用哪个方法，
    而静态变量和静态方法在编译的时候就将其与类绑定在一起，在编译的时候就决定了调用的方法、变量，和重写没有关系
       
        
构造函数是否可以私有：可以

    https://www.cnblogs.com/bigbigbigo/p/7596400.html

重写重载：

    重载：方法名一样，返回类型和参数类型不一样就可以
    
    重写：方法名，参数类型数量都用一样，返回类型也要一样，修饰符只能比之前的低或者等于
    
    声明为 final ，private的方法不能被重写。声明为 static 的方法不能被重写，但是能够被再次声明。
    final修饰类不能被继承

接口抽象类：
    
    抽象类：
        1：通过abstract关键字进行声明
        2：抽象方法必须为public，protected，如果为private无法被子类重写
        3：抽象类不能通过new方式创建对像，只能通过子类继承并实现父类方法才能创建对象
        4：抽象类中可以有抽象方法也可以有非抽象方法。
        5：存在抽象方法的类一定是抽象类。
      
     抽象方法：
        1：通过abstract关键字进行声明
        2：抽象方法没有方法体
        
     接口：
        1：通过interface关键字进行声明
        2：接口中可以声明变量，且被隐式的指定为public static final，且只能是public static final
        3：接口中的方法，被隐式的声明为public abstract方法且只能是public abstract方法，java8
        新增了default修饰的方法，和static方法都是非抽象方法
        4：一个类可以实现多个接口，且必须实现接口中的所有方法
        
         
    什么时候用接口，什么时候用抽象类（变向问接口和抽象类的区别）：
        
       1： 接口中的方法要全部实现，除了java8的default和static，抽象类中的非抽象方法可以被子类继承不需要重写。
       2： 接口中只有抽象方法，java8加了default和static方法，抽像类中可以包含非抽象方法
       3： 接口中只能是public static final ，而抽象类中有各种类型变量
       4： 一个类只能继承一个抽象类，但是可以实现多个接口
        
        


1. List，ArrayList，LinkList，HasSet的区别(https://blog.csdn.net/zhangqunshuai/article/details/80660974)

1. ArrayList扩容

arrylist迭代器遍历的时候为什么能删除数据,且不报错

hashmap链表长度小于多会变会链表

hashmap为什么是线程不安全的


1. 集合对列queue的使用


2. HashMap put 的过程，发生hash冲突怎么办（https://blog.csdn.net/hutongling/article/details/69943935）

    hashmap转换成链表或红黑树后查询的时间复杂度
    

    导致hash冲突的原因:
    
        俩对象的hashcode相同，但是俩对象不一定相等，俩对象相等他们的hashcode一定相同
    
        hashmap，把k，v组成一个node链表对象存放到数组table里面，通过key生成hashcode，在通过hashcode生产索引来决定这个k，v组成的对象的存储位置
        当hashcode相同，比较key是否相同，相同就把v的新值替换旧值，如果key不同则把这个新put进来的k，v链表对象和上一个不同key相同hashcode
        连标对象组成一个链表，也就是上一个对象存放了最新冲突的对象的引用，数组中存的是第一个插入的k，v组成的node对象
        （这个链表是由hashcode
        相同，key不同的数据组成的，由此会出现一个问题hashcode冲突越多，查询越慢，其中java8当中链表大小达到阀值8，会将链表转红黑树）
    
        尽量预设hashmap的数组值，不然当超过默认数组长度后，hashmap要扩容，这会导致重写计算每个值在数组中的存放位置
    
    5. HashMap的底层结构，如何保证HashMap线程安全，能不能存空值
    
            数据+链表+红黑树，key和value都可以为空，但是key不能重复，hashmap查询块插入慢
        
    6. HashMap 1.8 之后为什么使用了红黑树，链表插入的方式为什么变成了尾插法
            
           如果出现了哈希冲突，那么新加入的节点放在链表的最后面。
           
           为什么用红黑树：https://blog.csdn.net/danxiaodeshitou/article/details/108175535
           
               1.8是链表加红黑树的形式，当链表数量大于8就会转红黑树
               当红黑树的节点小于或等于 6 个以后，又会恢复为链表形态。
               链表的时间复杂读是O(n),红黑树时间复杂读O(logn)。明显红黑树的时间复杂度更低
               但是红黑树本身占用的空间是普通节点的两倍,所以当节点数大于一定数量的时候红黑树综合运行效率才比链表好
               而且链表数量大于8的情况很少。
               
               如果元素个数小于8个，红黑树的查询成本高，新增成本低
               如果元素个数大于8个，红黑树的查询成本低，新增成本高
           
           为什么用尾插：
           
                在头插法的情况下并发扩容存在链表成环的这种情况，改为尾插法避免了这种情况。虽然hashmap是非线程安全的
         
     HashMap 默认初始容量为什么是16
     
         https://blog.csdn.net/qq_33472553/article/details/114455598
         因为2的幂次方拥有更低的碰撞几率和更高的查询速率，而且16这个数不大不小，太小容易扩容，太大容易浪费。
         反观长度16或者其他2的幂，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。
            
    7. HashMap 扩容
    
            https://www.toutiao.com/i6674178445695517187/
            https://www.toutiao.com/i6674551125145813515/
            
            扩容方式：
            
            默认的初始容量是16，加载因子0.75 当数据容量到达16*075也就是12的时候，数据会进行扩容，扩充为原来容量的2倍
            下次扩容是数据量达到32*0.75,扩充为64。其中初始容量和加载因子在new hashmap的时候通过构造指定。一般初始容量为2的n次方
            当指定的容量不是2的n次方的时候，容量会取2的n次方中最接近且大于指定值的数。然后把原数组中的值遍历，重写计算hash来确定每个node在
            table数组中的存储位置。
            
            Hash的公式---> index = HashCode（Key） & （Length - 1）
    
    8. HashMap是线程安全的吗，介绍几种线程安全的HashMap

        https://blog.csdn.net/my_springlove/article/details/116082810
        https://blog.csdn.net/u011277123/article/details/90748084
        
        
ConcurrentHashMap  
        
        简单介绍：https://www.jianshu.com/p/4e03b08dc007
        
        



共享锁，排他锁：
    
    https://blog.csdn.net/weixin_44008655/article/details/107198391
    共享锁（读锁）：SELECT … LOCK IN SHARE MODE
    共享锁（写锁）：select ... from where id=1 for update
    表锁：lock tables t read/write
    
    读锁是共享的，可以通过lock in share mode实现，其他事务可以继续加读锁，但是不能加写锁
    
    写锁是排他的，它会阻塞其他的写锁和读锁。从颗粒度来区分，可以分为表锁和行锁两种。
    
    表锁会锁定整张表并且阻塞其他用户对该表的所有读写操作，比如alter修改表结构的时候会锁表。
    
死锁：
    
    是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。
    此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的过程称为死锁
    
多线程

   减少上下文切换：
    
        无锁并发编程：多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一 些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。
        
        CAS算法：Java的Atomic包使用CAS算法来更新数据，而不需要加锁。
        
        使用最少线程：避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这 样会造成大量线程都处于等待状态
        
        使用协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。
   
   join：
   
       实现主线程等待子线程结束后在继续运行
       具有使线程排队运行的作用，类似同步效果，内部使用wait()方法进行等待
       
   停止线程的方法：
        
        可以使用return和异常两种方式释放锁，stop不推荐
        
   判断线程是否停止（通过interrupt和isInterrupt进行判断）
    
        this.interrupt()具有清除状态的作用
        this.isInterrupt()不清除标志状态
        
   wait和sleep
    
        wait会释放锁，sleep不会     
        
   多线程加锁
   
        1：synchronized（持有对象锁）
        
        2：ReentrantLock（排他锁）（持有对象锁）
        
               公平锁：线程获取锁的顺序是按照线程加锁的顺序分配的
                    ReentrantLock lock=new ReentrantLock(true)
                    try{
                         lock.lock();
                          业务方法;
                    }finally{
                        lock.unlock();
                    }
                   
                   
      
               非公平锁：线程获取锁的顺序是随机的
                    ReentrantLock lock=new ReentrantLock(false)
                    try{
                         lock.lock();
                          业务方法;
                    }finally{
                        lock.unlock();
                    }
                    
        3：ReentrantReadWriteLock（分为读锁（共享锁）和写锁（排他锁）两部分）（持有对象锁）
            
                读锁功能：允许多个线程同时获取锁
                    ReentrantReadWriteLock lock=new ReentrantReadWriteLock();
                    try{
                        lock.readLock().lock;
                        业务操作;
                    }finally{
                        lock.readLock().unlock();
                    }
                    
                写锁功能：同一时间只能有一个线程获取锁
                 
                    ReentrantReadWriteLock lock=new ReentrantReadWriteLock();
                    try{
                        lock.writeLock().lock;
                        业务操作;
                    }finally{
                        lock.writeLock().unlock();
                    }
                 
                 注意：读和写是互斥的，写和写也是互斥的，读和读是共享的。也就是多线程去读可以同时获取锁，而涉及到写操作一旦写获取到对象
                 锁，读操作和其他写操作只能等待锁的释放。   
                            
    
   如何实现线程等待通知  
        
             wait/notify
                wait方法会立马释放锁，notify只有当同步块代码执行完成才会释放锁
             
             condition
             public class ConditionWs{
                ReentrantLock lock=new ReentrantLock(true);
                Condition condition=lock.newCondition();
                public void await(){
                    try{
                         lock.lock();
                         //让线程等待
                         condition.await();
                          业务方法;
                    }finally{
                        lock.unlock();
                    }
                }
                
                
                public void signal(){
                    try{
                         lock.lock();
                         //通知
                         condition.signal();
                          业务方法;
                    }finally{
                        lock.unlock();
                    }
                }
             }
             
            
            signalAll()通知所有
            class service
            Condition condition=lock.newCondition();
            
            await1(){
             condition.await();
            }
            
             
            await2(){
             condition.await();
            }
           
            signalAll(){
              condition.signalAll();
            }
                
            ThreadA a = new ThreadA(service);      
            ThreadB b = new ThreadB(service);      
            a.await1();
            b.await2();
            //直接用service对象调用的话用用的是主线程
            service.signalAll();
            
            如果想通知部分线程需要声明多个Condition对象
        
   synchronized和volatile的区别
    
         `volatile ` 强制线程从公共堆栈中取 `volatile`修饰的变量
         `synchronized` 实现多线程资源同步访问,synchronized同时具有将线程工作内存中的私有变量与公共内存中的变量同步的功能
          volatile实现变量在多线程间可见
           
         `volatile` 只能保证可见行和顺序性，不能保证原子性，`synchronized` 可以保证修改可见行和原子性，因为他将私有内存和公共内存中的数据进行了同步
         `volatile` 只能用来修饰变量，`synchronized` 可以修饰类，变量及方法
         `volatile` 不会造成线程阻塞，`synchronized` 可能会造成线程阻塞
          synchronized可以具有将线程工作内存中的私有变量与公共内存中的变量同步的功能
    
   ReentrantLock（Lock是ReentrantLock的父类）和  synchronized的区别
          
          ee
         
   ThreadLocal用过吗
    
        每个线程都有自己的共享变量
        
   InheritableThreadLocal:
   
        子线程获取父线程继承的值
    
   可重入锁是什么，为什么要重复获取，第一次的时候不是已经获取了吗
    
     一个线程可以多次获取同一个对象的锁，当一个线程获取了一个对象锁，此时对象锁没有释放，当想再次获取该对象锁是没有问题的
     这也证明在一个synchronized方法或方法块中可以调用本类的其他synchronized方法或方法块是可以永远得到锁的
     
     会出现死锁（当你有 一个类A，B两个成员方法同时加锁，而A调用B时就会加两次锁，如果是不可重入锁就会死锁）
     
     第一次还没执行完，锁还没有释放
     
     当存在父子类继承关系时，子类完全可以通过可重入锁调用父类方法。
     
     出现异常锁自动释放
     
     同步不具有继承性

   synchronized的锁升级过程
        
        锁一共四种状态，由低到高分别是：无锁状态，偏向锁状态，轻量级锁状态，重量级锁状态，
        这几个状态会随着竞争情况逐渐升级。
        锁一旦升级就不能降级（目的是提高获得锁和释放锁的效率）
   
   
   偏向锁：
        
        引入偏向锁的目的：因为经过HotSpot的作者大量的研究发现，大多数时候是不存在锁竞争的，常常是一个线程多次获得同一个锁，因此如果每次都要竞争锁会增大很多没有必要付出的代价，为了降低获取锁的代价，才引入的偏向锁。
    
        
   线程的生命周期：
    
        start,running,waiting,blocked,dead
   cas：
      
     https://www.jianshu.com/p/ae25eb3cfb5d
     什么是cas：
        Compare And Swap，cas操作就是乐观锁。每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。
        
        CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。
        
        更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。
        如果不一致会重写获取预期值尝试更新，直到更新成功为止。
     
     CAS的缺点：
     
         1.CPU开销较大
         在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。
         
         2.不能保证代码块的原子性
         CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证3个变量共同进行原子性的更新，就不得不使用Synchronized了。
   
   synchronized和cas：
    
        synchronized是悲观锁，这种线程一旦得到锁，其他需要锁的线程就挂起的情况就是悲观锁。
        
        CAS操作的就是乐观锁，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。
        
        Synchronized虽然确保了线程的安全，但是在性能上却不是最优的，Synchronized关键字会让没有得到锁资源的线程进入BLOCKED状态，而后在争夺到锁资源后恢复为RUNNABLE状态，
        这个过程中涉及到操作系统用户模式和内核模式的转换，代价比较高
        
    
   自旋锁：
       
       https://www.jianshu.com/p/9d3660ad4358?utm_source=oschina-app
       是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。
   
   juc:
    
        
        

多线程框架：
    
        主要参考：https://www.jianshu.com/p/7ab4ae9443b9
        https://blog.csdn.net/fanrenxiang/article/details/79855992
      线程池作用
          限制线程个数，避免线程过多导致系统运行缓慢或崩溃。
          不需要频繁的创建和销毁，节约资源、响应更快。

      参考：https://www.jianshu.com/p/7726c70cdc40 以及java并发编程的艺术
      https://blog.csdn.net/tongdanping/article/details/79604637
      https://blog.csdn.net/weixin_40304387/article/details/80508236
      阻塞队列（生产者消费者模式）：
            队列容量不足自动阻塞，队列容量为 0 自动阻塞
            
      阻塞队列：
            ArrayBlockingQueu：基于数组结构的有界阻塞队列，队列按照先进先出原则对元素进行排序
            
            LinkedBlockingQueue：基于链表结构的阻塞队列，队列按照先进先出排列元素，吞吐量通常高于ArrayBlockingQueu
            
            PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。 
            ·DelayQueue：一个使用优先级队列实现的无界阻塞队列。 
            ·SynchronousQueue：一个不存储元素的阻塞队列。
             ·LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 
             ·LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列
             
      为什么要用阻塞队列，阻塞队列相对于其他队列有什么优点。
      
      
      Executor框架：
        
         execute()和submit()的区别：
            execut处理没有返回值的方法，submit处理有返回值的方法
            
      Executors提供了四种方法来创建线程池。
      
          newFixedThreadPool() :创建固定大小的线程池。
          newCachedThreadPool(): 创建无限大小的线程池，线程池中线程数量不固定，可根据需求自动更改。
          newSingleThreadPool() : 创建单个线程池，线程池中只有一个线程。
          newScheduledThreadPool() 创建固定大小的线程池，可以延迟或定时的执行任务。
      
      线程池参数：
        
            corePoolSize：线程池基本大小Callable
            maximumPoolSize：最大线程数
            keepAliveTime：线程池的工作线程空闲后，保持存活的时间
            runnableTaskQueue：任务队列，用于保存等待执行的任务的阻塞队列
            ThreadFactory：线程工厂，用于创建线程，指定线程名称
            RejectedExecutionHandler：饱和策略，当队列和线程池都满了，说明线程池处于饱和状 态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法 处理新任务时抛出异常。
            在JDK 1.5中Java线程池框架提供了以下4种策略。
                  
                  ·AbortPolicy：直接抛出异常。
                  
                  ·CallerRunsPolicy：用调用者所在线程来运行任务。
                  
                  ·DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
                  
                  ·DiscardPolicy：不处理，丢弃掉。
                  
                  当然，也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录 日志或持久化存储不能处理的任务。
            
            
       线程池ThreadPoolExecutor执行过程：
       
            线程池判断核心线程池里的线程是否都在执行任务。
            如果不是，则创建一个新的工作 线程来执行任务。
            如果核心线程池里的线程都在执行任务，则进入下个流程。 
            2）线程池判断工作队列是否已经满。
            如果工作队列没有满，则将新提交的任务存储在这 个工作队列里。
            如果工作队列满了，则进入下个流程。 
            3）线程池判断线程池的线程是否都处于工作状态。
            如果没有，则创建一个新的工作线程 来执行任务。如果已经满了，则交给饱和策略来处理这个任务。
       
       Callble和Runnable的区别：
        
            https://blog.csdn.net/sinat_39634657/article/details/81456810
            allable 和 Future接口的区别
            
             Callable规定的方法是call()，而Runnable规定的方法是run(). 
             Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。  
              call()方法可抛出异常，而run()方法是不能抛出异常的。 
              运行Callable任务可拿到一个Future对象， Future表示异步计算的结果。 
              它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。 
              通过Future对象可了解任务执行情况，可取消任务的执行，还可获取任务执行的结果。 
             Callable是类似于Runnable的接口，实现Callable接口的类和实现Runnable的类都是可被其它线程执行的任务。
        
            
       线程池的拒绝策略
        
             在JDK 1.5中Java线程池框架提供了以下4种策略。
                              
                              ·AbortPolicy：直接抛出异常。
                              
                              ·CallerRunsPolicy：只用调用者所在线程来运行任务。
                              
                              ·DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
                              
                              ·DiscardPolicy：不处理，丢弃掉。
                              
                              当然，也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录 日志或持久化存储不能处理的任务。
        创建多线程的方式              
        
    
        Java线程池提交一个任务，在未达到核心线程数之前，为何不复用之前创建的线程，而是直接新建？：
        
        阻塞队列：
            https://blog.csdn.net/yamadeee/article/details/100181893
        
        Future和FutureTask：
            https://www.jianshu.com/p/9906f84b9d4d
            
            Future是一个接口，是无法生成一个实例的，所以又有了FutureTask。
            FutureTask实现了RunnableFuture接口，
            RunnableFuture接口又实现了Runnable接口和Future接口。
            所以FutureTask既可以被当做Runnable来执行，也可以被当做Future来获取Callable的返回结果
        
        
5. aqs实现原理        

    主要参考：https://zhuanlan.zhihu.com/p/338823610

    https://www.jianshu.com/p/279baac48960
    https://zhuanlan.zhihu.com/p/338823610
    
    https://www.cnblogs.com/wang-meng/p/12816829.html
    https://www.cnblogs.com/blackmlik/p/12952701.html
    https://blog.51cto.com/u_9291927/2063376
    https://www.jianshu.com/p/82ae4b609441
    https://www.jianshu.com/p/279baac48960
    
    aqs：AbstractQueuedSynchronized（AQS）抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch...
    
    通过实现aqs。来开发自己的并发工具类
    核心：state代表锁状态，双向队列没有抢到锁的线程组成，exclusiveOwnerThread保存获取锁的线程
    
    子类继承AbstractQueuedSynchronized并重写tryAcquire（获取锁方法，自定义获取锁逻辑）
    
    获取锁失败，将当前线程封装成node添加到双向队列尾部，如果队列尾部为空就初始化，不为空就cas自旋尝试加入到队列尾部
    
    进入队列后不断获取锁或者挂起，取消
    
    
    
4. Mysql
   
       mysql索引
       
           什么是叶子节点和非叶子节点（没有儿子的节点就是叶子节点）
           结点的孩子结点个数即为该结点的度.
           度为0的结点叫叶子结点.
           处在树的最顶端(没有双亲)的结点叫根结点.
           
           msyql的<=>
           https://www.cnblogs.com/abclife/p/11488613.html
       
           Hash索引仅仅能满足"=",“IN"和”<=>"查询，不能使用范围查询。也不支持任何范围查询，例如WHERE price > 100。
           由于Hash索引比较的是进行Hash运算之后的Hash值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的Hash算法处理之后的Hash值的大小关系，
           并不能保证和Hash运算前完全一样。
           
           https://blog.csdn.net/wangfeijiu/article/details/112454405
           B+树索引和哈希索引的明显区别是：
           如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；这有个前提，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；
           如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索； 
           哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；  
           哈希索引也不支持多列联合索引的最左匹配规则；
           B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。
       
           B树资料
           https://cloud.tencent.com/developer/article/1691641
           
           
           为什么用B+数而不是而不是 B 树、Hash、红黑树或二叉树：
                
                B 树：不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低；
                Hash：虽然可以快速定位，但是没有顺序，IO 复杂度高；
                
                二叉树：树的高度不均匀，不能自平衡（极端情况会变成线性结构，查询又变成了全部遍历），查找效率跟数据有关（树的高度），并且 IO 代价高；
                
                红黑树：树的高度随着数据量增加而增加，IO 代价高。 ###为什么 InnoDB 要使用 B+ 谁来存储索引？
                    B+Tree 中的 B 是 Balance，是平衡的意思，它在经典 B Tree 的基础上进行了优化，增加了顺序访问指针，
                    在B+Tree 的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的 B+Tree，
                    这样就提高了区间访问性能：如果要查询 key 为从 18 到 49 的所有数据记录，当找到 18 后，
                    只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率（无需返回上层父节点重复遍历查找减少 IO 操作）。
                    
                索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上，这样的话，索引查找过程中就要产生磁盘 IO 消耗，
                相对于内存存取，IO 存取的消耗要高几个数量级，所以索引的结构组织要尽量减少查找过程中磁盘 IO 的存取次数，从而提升索引效率。
                综合所述，InnDB 只有采取 B+ 树的数据结构存储索引，才能提供数据库整体的操作性能。
           
       从数据结构的角度说一下mysql索引：
       
       为什么用b+，为什么不用hash：
            https://bbs.huaweicloud.com/blogs/118418
       
           https://bbs.huaweicloud.com/blogs/267675
       
       count（*）count（1），count（字段），count（主键）
       https://bbs.huaweicloud.com/blogs/218243
       
       
       mysql优化：
       
        https://blog.csdn.net/weixin_44981707/article/details/108506087
       
       1：各种问题
       https://bbs.huaweicloud.com/blogs/218243
       
       索引类型：
            
            https://blog.csdn.net/wangfeijiu/article/details/113409719?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162512358916780274128155%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=162512358916780274128155&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v2~rank_v29-1-113409719.pc_v2_rank_blog_default&utm_term=mysql&spm=1018.2226.3001.4450
            索引结构进行分类：
                B-Tree,B+Tree，HASH
                
            按照功能划分：
            
             普通索引
             唯一索引
             主键索引
             全文索引：
             
            按列数划分：
            
                单例索引：
                
                组合索引
                
            按照物理分类：
            
                聚簇索引：
                
                非聚簇索引(也可以称辅助索引或二级索引)：
                
       
       
       什么是聚簇和非簇集索引：
            
            https://www.cnblogs.com/jiawen010/p/11805241.html
            聚簇索引：聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。聚簇索引列的顺序就是表记录的物理顺序，频繁更新会影响性能。
            一般建表会用一个自增主键做聚簇索引，没有的话MySQL会默认创建。
            
            聚簇索引按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。
            这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引。
            
            非聚簇索引：也称辅助索引，就是一个为了寻找主键索的引二级索引，然后通过主键索引查询数据
       
       索引失效：
            
            https://www.jianshu.com/p/e978e4a0be34?utm_campaign=haruki&utm_content=note&utm_medium=reader_share&utm_source=weixin
            where语句中使用!=, <>,判断是否为空，使用or连接条件,对没有添加索引的字段进行in或者not in，条件中使用参数，
            字段进行表达式操作（where num/2=100）,对字段进行函数操作
            like %开头   
       
       索引优化：
            https://zhuanlan.zhihu.com/p/59566131
            1：不要对有大量重复值的字段建立索引，如性别
            2：索引不是越多也好，索引提高的查询的效率但是降低了insert和update的效率，因为insert和update可能会重写建立索引
            索引数量最好不要超过6个
            3：尽量不要更新聚簇索引(主键就是聚簇索引)，因为聚簇索引列的顺序就是表记录的物理顺序，表记录顺序的调整会消耗大量资源
            4：尽量使用数字类型代替字符串，因为引擎在处理查询和连接时，会逐个比较字符串中每一个字符，而对于数字类型而言只需要比较一次就够了
            5；不要用select * ，要用具体字段代替。select *需要查询列表上有什么字段，直接用字段就省了一步。
            6：如果只查一条数据用limit 1 这样只要找到一条数据就不会继续扫描
            7：where，join，ORDER BY语句里面的条件字段尽量用索引
            8：通过explain去查看执行计划
            9：对于非常小的表，大部分情况下简单的全表扫描更高效
            10：当该列修改性能要求远远高于检索性能时，不应该创建索引
            使用短索引，短索引不仅可以提高查询速度，更能节省磁盘空间和 I/O 操作；
            索引列排序，MySQL 查询只使用一个索引，因此如果 where 子句中已经使用了索引的话，那么 order by 中的列是不会使用索引的，因此数据库默认排序可以符合要求的情况下，不要进行排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引
            
       explain使用： 
       
            https://blog.csdn.net/lvhaizhen/article/details/90763799
       
       sql优化 like%的解决方案
       
       
       char和varchar有啥区别
           - 定长和变长：char 长度固定，varchar 长度可变，
           
           char如果插入的长度小于定义长度时，则用空格填充
           ，
           varchar小于定义长度时，还是按实际长度存储，插入多长就存多长，
           
           因为char长度固定，所以char的存取速度还是要比varchar要快得多，方便程序的存储与查找，是以空间换取时间效率，
           varchar则刚好相反，以时间换空间，却会产生空间碎片。
           
            CHAR 比较适合长度较短的字段和固定长度的字段，如身份证号、手机号等
           
           char对英文占一个字节，汉子两个字节，varchar对英文和汉字都是两个字节、
           
           - 存储的容量：对 char 来说，最多能存放的字符个数 255，和编码无关，
           而 varchar 最多能存放 65532 个字符，varchar的最大有效长度由最大行大小和使用的字符集确定
        
       union all和union的区别
            UNION和UNION ALL关键字都是将两个查询结果并为一个。
            不同的是union在表连接后会进行排序去重，而union all不会，所以union all效率比union高
              
     
       
    
       
       
       left join的过程，也就是问sql解析过程
       
           https://www.cnblogs.com/annsshadow/p/5037667.html
       
       mysql innodb和myisam的区别
             myisam，不支持事务和行级锁，而且崩溃后无法安全回复。
             MyISAM 只有表级锁(table-level locking)，而 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。
             MyISAM 不支持外键，而 InnoDB 支持。
             MyISAM 不持数据库异常崩溃后的安全恢复，InnoDB支持 数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 redo log
             是否支持 MVCC MyISAM 不支持，而 InnoDB 支持。
             MyISAM支持全文索引, InnoDB部分版本不支持(但可以使用Sphinx插件)
             
       MVCC：MVCC多版本并发控制(Multi-Version Concurrency Control)是MySQL中基于乐观锁理论实现隔离级别的方式，用于实现读已提交和可重复读取隔离级别。
        mvcc只在读已提交和可重复读两种隔离级别情况下生效
        
       https://blog.csdn.net/sanyuesan0000/article/details/90235335
                          
       mysql如何保证事务的持久性和原子性，隔离性
            MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，
            通过 undo log(回滚日志)在增删改时记录回滚信息，当出现异常或者调用回滚命令的时候，就利用之前记录的回滚日志进行回滚操作。 来保证事务的原子性。
           
            MySQL InnoDB 引擎通过 锁机制、MVCC 等手段来保证事务的隔离性（ 默认支持的隔离级别是 REPEATABLE-READ ）。
            保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障
            
       mysql主从复制过程
            主从优点：读写分离，数据备份，提高数据库并发
            https://blog.csdn.net/darkangel1228/article/details/80004222
            概念：
                bin-log：是一个二进制文件，记录所有sql语句
                relay-log:重做日志
                
                
            1：master提交事务后，将sql写入bin-log
            2：slave和master连接
            3：master新建一个dump线程，将bin-log推送给slave
            4：slave启动一个io线程读取master推送的bin-log，并保存到relay-log中继日志中
            4：slave再开启一个sql线程读取relay-log中的事件并执行，完成同步。
            5：slave同步自己的bin-log
            
     ![image-20210609215206870](https://img-blog.csdnimg.cn/img_convert/6708b59d6968260d010ca217ded8ae6b.png)
     
        
        
       如何解决主从同步失败，从库升级为主库后数据丢失问题：
        
            全同步复制：
                
                主库写入binlog后强制同步日志到从库，所有的从库都执行完成后才返回给客户端，但是很显然这个方式的话性能会受到严重影响。
            
            半同步复制：
                
                和全同步不同的是，半同步复制的逻辑是这样，从库写入日志成功后返回ACK确认给主库，主库收到至少一个从库的确认就认为写操作完成。
                
       redo log undo log：
        
            https://blog.csdn.net/weixin_39522698/article/details/110797185
            
       
       mysql修改索引会不会锁表：
        
            mysql 5.6支持在线ddl操作，在对表进行alter table 时，对该表的增，删，改，查均不会锁表
            但是ddl操作触发了表锁，此时对该表的增，删，改，查均会被阻塞
       
       
        
                 
            
       ACID事务特性 ：
        
            原子性：事务涉及的操作要么全部完成，要么完全不起作用
            
            一致性：事务执行前后，数据保存一致。例如转账，a转给b，不能存在a的钱扣除了，b没有增加。
            
            隔离性：一个事务执行过程中，不受其它事务干扰
            
            持久性：事务提交后，他对数据库的操作是持久的，即使数据库发生故障也不应该对事务操作的数据产生影响
       
       并发事务带来的问题：
       
            脏读：读未提交，一个事务，读取了另一个事务修改后未提交的数据。
            
            丢失数据：也是读未提交导致的，事务a修改了某个数据，事务b也同时修改了，事务a在事b务修改完成后，读取修改的数据发现数据错误
            
            
            不可重复读：一次事务操作中多次读取同一个数据，事务a在第一次读取后，事务b修改了该数据，事务a再次读取发现两次读取的数据不一致
            
            幻读：事务a读取数据，事务b插入了几条数据，事务a再次读取的时候发现多了数据
             
             
       Mysql事务隔离事务隔离级别
       
            读未提交： 读取未提交的数据，可能出现脏读，幻读，不可重复读
            
            读已提交： 读取已经提交的数据，不会出现脏读，但是会出现幻读，和不可重复读。
            
            可重读读（Innodb默认）：对同一字段的多次读取结果都是一致的，除非事务是被本身数据修改。可以防止脏读和不可以重复读
            
            可串行化：最高的隔离级别，完全遵循acid原则，事务逐个执行，可以防止脏读，幻读，不可重复读。
            
       Mysql5.7 索引where和orderby排序问题:
            
            https://blog.csdn.net/oHeiZhiShi123/article/details/104840183
            
            
       select for update:
       
            
       
       mysql如何实现可重复读：
            
           mvvc：多版本并发控制，解决不可重复读问题，间隙锁解决幻读
        
           通过mvvc实现，通过在每行记录后面添加两个隐藏列，一个保存行的创建时间，，一个保存行的过期时间，
           并且存储的不是实际的时间而是系统版本号。没次开启一个事务，系统版本号都会自动递增。并将事务开始时刻的系统版本
           号作为事务的版本号。
           
           更新操作：
                复制原来的行，并同时设置复制行的事务版本号为当前事务版本好，设置原来行的事务删除版本号为当前事务版本号。
           删除操作：
                执行删除不是真正的删除，而是将删除时间设置为当前事务的版本号
           
           插入操作
                插入数据，同时设置插入行的创建时间为当前事务获取的系统版本号。
           
           mvccc查询逻辑
            
                查询数据行中创建时间，小于等于当前事务版本号的数据（确保了读取到的数据是当前事务开始前已经存在的数据，或者是自身事务改变过的数据）
                查询删除版时间为空，或者大于当前事务版本号的数据（保证数据是事务开启前没有删除的数据）
            
          特点：（假设事务a和事务b处理相同数据）
              因为MySQL的可重复读，对事务B进行查询时，事务A提交的更新不会影响到事务B。
          　　但是对事务B进行更新时，事务A提交的更新会影响到事务B。
          
          
       什么时候锁行，什么时候锁表
        
            https://bbs.huaweicloud.com/blogs/213380
       
       如何避免锁表，锁行
       
       
       for update:
        
            https://zhuanlan.zhihu.com/p/74875550
       
       事务锁：
        
            https://blog.csdn.net/chonywang/article/details/102693121
            
            
       MySQL在对DDL操作注意事项，以及添加索引是否会锁表：
       
           1：mysql 5.6支持在线ddl操作，在对表进行alter table 时，对该表的增，删，改，查均不会锁表。（我线上用的是：MySQL 5.6.26）
       
           2：但如果在该表被访问时，执行DDL操作会导致表锁，会阻塞对表的任何操作（所以在进行上线操作时一定要观察一下是否有对表操作的慢的查询语句或者事务）
       
           3：如果有慢查询 -> 只有慢查询结束了之后，才能创建索引和其他的操作
   
        
       mysql内部执行过程：
        
            1：客户端连接mysql服务器：
            
            2：查询是否有缓存，有直接返回数据
            
            3：分析器，分析sql合规性
            
            4：优化器优化sql
            
            5：执行器执行sql
            
        mysql缓存优缺点：
            
            优点：有缓存直接返回，效率高
            
            缺点：任何更新操作都会清空缓存，缓存非常容易失效，缓存是默认开启的，8.0后删除了缓存功能
            
        mysql常用引擎：
            
             InnoDB、MyISAM、Memory
             
             
        mysql可以针对不同的表设置不同的数据库引擎：
        
            可以
                
            在 create table 语句中使用 engine=引擎名（比如Memory）来设置此表的存储引擎
            
            create table student(
             id int primary key auto_increment,
             username varchar(120),
             age int
            ) ENGINE=Memory
        
        如何避免幻读：
        
            间隙锁（Gap Lock）是可重复读级别下才会有的锁
            使用间隙锁，它锁的了行与行之间的间隙，能够阻塞新插入的操作 
            他锁定一个范围，单不包括记录本身；
            间隙锁的引入也带来了一些新的问题，比如：降低并发度，可能导致死锁。
        
            Next-Key Lock — 锁定一个范围，包括记录本身
        explain中using index和using index condition
            
            https://www.cnblogs.com/zhp-king/p/7250810.html
              
        最左前缀：
            
            https://blog.csdn.net/sinat_41917109/article/details/88944290
            https://blog.csdn.net/oHeiZhiShi123/article/details/104840183
            https://zhuanlan.zhihu.com/p/34241236
            
        前缀索引：
            给一个字段的局部加索引：有以下俩种方式
            
            alter table t add index index_phone(phone(6));
            create index index_phone on t(phone(6));
            
            缺点：不能在 order by 或者 group by 中触发前缀索引，也不能把它们用于覆盖索引。
            
            
5. Mybatis常用标签

   - `resultMap, parameterMap, sql, include`

   - `where, if, bind, foreach`
   -  `choose when otherwise`
   - `selectKey`
   - `select, insert, update, delete`

6. new 一个字符串的时候会做什么操作

   - 首先会在字符串常量池中查看字符串是否存在，不存在则先在常量池中创建
   - 存在或在常量池中创建之后，在堆中分配空间，然后栈的引用指向堆中分配的空间

7. 分布式事务的解决方案

8. 简述一下@Autowired

9. @Autowired 和 @Resource 

   - @Resource的作用相当于@Autowired，均可标注在字段或者属性的setter方法上
   - @Autowired默认按类型装配，若想使用名称装配可以结合`@Qualifier`注解，需要注入的对象必须存在，若要允许null值，可以设置它的required属性为false
   - @Resource 是JDK1.6支持的注解，默认按照名称 name 进行装配，没有指定name属性默认取字段名，当找不到与名称匹配的bean时才按照类型进行装配，但如果name属性一旦指定，就只会按照名称进行装配
   - @Resource 若同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常

10. 简述一下Spring AOP

    https://mp.weixin.qq.com/s/JEQ9ha9NhZ-k3SUNlRx8Jw
    https://www.cnblogs.com/joy99/p/10941543.html
    https://www.cnblogs.com/qlqwjy/p/7550609.html
    面向切面编程，通过动态代理的方式进行实现，主要是在操作在方法前后进行操作，动态为类添加方法和属性，修改原方法进行增强
    
    主要分为
    
    静态代理 ：是编译期间进行增加（代理类和被代理类需要实现相同的接口或者父类），
    jdk动态代理（通过接口方式实现）：一个是调用期间进行增强，代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象，也就是代理对象是通过该接口的反射机制创建的
    代理对象=Proxy.newProxyInstance(被代理对象.getClass().getClassLoader(),被代理对象.getClass().getInterfaces(), this);
    （代理对象不需要实现接口,但是目标对象一定要实现接口,否则不能用jdk动态代理），
    
    cglib代理（通过继承的方式实现：他的底层原理是基于 asm 第三方框架，通过修改字节码生成成成一个子类，然后重写父类的方法，实现对代码的增强）：
    cglib（因为是通过继承方式实现，被代理的类不能为final,否则报错，且方法为final，static,private也无法进行代理）
    
    主要是在方法前后，异常后进行增强操作
    - 动态代理 jdk-实现接口，cglib-继承
    - 通知，切点，连接点，切面
    - 引入：允许向现有的类中添加方法或属性
    - 织入：将切面应用到目标对象来创建的代理对象过程

11. 简述一下Spring 声明式事务

    https://mp.weixin.qq.com/s/JEQ9ha9NhZ-k3SUNlRx8Jw
    - 7种事务传播行为
    
    1.PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，这也是通常我们的默认选择。
    
    2.PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。
    
    3.PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行。
    
    4.PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
    
    5.PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。
    
    6.PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。
    
    7.PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。‘
    
    - 4种隔离级别，默认和数据库的隔离级别一致
    https://snailclimb.gitee.io/javaguide/#/docs/database/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB(%E5%9B%BE%E6%96%87%E8%AF%A6%E8%A7%A3)?id=%e4%ba%8b%e5%8a%a1%e7%9a%84%e7%89%b9%e6%80%a7acid

spring aop失效的场景
        
       jdk动态代理：
            
            
            
       
       cglb动态代理：
            因为是通过继承方式实现，被代理的类不能为final,否则报错，且方法为final，static,private也无法进行代理
            
            
      
    
spring事务失效的场景
    
    1：数据库引擎不支持事务，比如myisam，innodb是支持事务的
    
    2：没有被spring管理
    
    3  注解是通过aop实现的，所以spring aop失效会导致注解失效
    
    4：自身调用，必须通过spring注入方式调用
     
    5：数据源没有配置事务管理器
    
    6：事务传播级别设置为PROPAGATION_SUPPORTS，以非事务方式执行操作，如果当前存在事务，就把当前事务挂起
    
    7：方法通过try catch捕获异常后不抛出。
    
    8：Spring 默认只为 RuntimeException 异常回滚事务，可以通过事务注解中的rollbackFor属性设置异常类型
 
spring依赖注入的方式：
    
    1：注解注入：Autowired（自动从spring的上下文找到合适的bean来注入），Resource（指定名称注入）
    
    2：构造器注入
    
    3：set方式注入
    
解释Spring支持的几种bean的作用域

    Spring框架支持以下五种bean的作用域：
    
    singleton : bean在每个Spring ioc 容器中只有一个实例。 
    prototype：一个bean的定义可以有多个实例。 
    request：每次http请求都会创建一个bean，该作用域仅在基于web的Spring ApplicationContext情形下有效。 
    session：在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的 Spring ApplicationContext情形下有效。
    global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例。该作用域仅在基 于web的Spring ApplicationContext情形下有效。
    
    注意： 缺省的Spring bean 的作用域是Singleton。使用 prototype 作用域需要慎重的思考，因为频繁 创建和销毁 bean 会带来很大的性能开销。    
    
Spring框架中的单例bean是线程安全的吗？

    不是线程安全的，spring bean大多数情况都是无状态，有状态的化需要处理线程安全问题，最简单的方式
    是把bean的作用域用单例singleton变成prototype,这样请求bean就相当于new bean();

    有状态就是有数据存储功能。 无状态就是不会保存数据。

spring如何解决以构造函数方式注入的循环依赖
    
    什么是循环依赖：
    
        一个或者多个对象直接或者间接依赖形成一个环。
        例如：A中需要引用B，B中同时引用A，如果不解决循环依赖，a会等待b先创建，b又会等待a创建 形成死循环
     
    解决循环依赖的前提：
        
        1：必须是单例
        2：相互依赖的bean，不全是构造器方式方式注入（实例化和初始化的流程分开了的方式解决循环依赖，所以都是构造的化就不行了）
     
    通过三级缓存解决循环依赖：
        
        第一级缓存：用来保存实例化、初始化都完成的对象
        
        第二级缓存：用来保存实例化完成，但是未初始化完成的对象
        
        第三级缓存：用来保存一个对象工厂，提供一个匿名内部类，用于创建二级缓存中的对象
    

spring生命周期：
    
    https://blog.csdn.net/u010979642/article/details/108972920
    https://mp.weixin.qq.com/s/JEQ9ha9NhZ-k3SUNlRx8Jw
    Springboot启动扩展点超详细总结，再也不怕面试官问了
    
    1：实例化，创建一个Bean对象：
        1：InstantiationAwareBeanPostProcessor：接口是BeanPostProcessor的子接口，可以在bean实例化前后进行操作
            接口中具体方法如下：
            postProcessBeforeInstantiation：实例化bean之前，相当于new这个bean之前
            postProcessAfterInstantiation：实例化bean之后，相当于new这个bean之后
            postProcessPropertyValues：bean已经实例化完成，在属性注入时阶段触发，@Autowired,@Resource等注解原理基于此方法实现
            postProcessBeforeInitialization：初始化bean之前，相当于把bean注入spring上下文之前
            postProcessAfterInitialization：初始化bean之后，相当于把bean注入spring上下文之后

        2：BeanFactoryPostProcessor：实例化之前调用
        
    2：填充属性，为属性赋值：
        InstantiationAwareBeanPostProcessor：
        postProcessPropertyValues：bean已经实例化完成，在属性注入时阶段触发，@Autowired,@Resource等注解原理基于此方法实现
    3：初始化：
        1：如果实现了xxxAware接口，通过不同类型的Aware接口拿到Spring容器的资源，并且Aware接口都是在初始化前执行
        比如：
        BeanNameAware，触发点在bean的初始化之前，也就是postProcessBeforeInitialization之前，这个类的触发点方法只有一个：setBeanName
                      使用场景为：用户可以扩展这个点，在初始化bean之前拿到spring容器中注册的的beanName，来自行修改这个beanName的值。
                      
        BeanClassLoaderAware，
        BeanFactoryAware：实现该接口后可以获取BeanFactory的实例引用
                           * 就可以让当前实现类Bean拥有访问Spring容器的能力。缺点：导致代码与spring的api耦合在一起
        EnvironmentAware，
        ApplicationContextAware（获得ApplicationContext中(spring上下文中)的所有bean）

        
        2：InitializingBean（当BeanFactory将bean创建成功，并设置完成所有它们的属性后我们想在这个时候去做出自定义的反应，
                         比如检查一些强制属性是否被设置成功，这个时候我们可以让我们的bean的class实现InitializingBean接口，以被触发）,
          也可以通过@PostConstruct
          
       
                         
        3：BeanPostProcessor，所有bean初始化前后都回调用该接口实现类中的初始化前和初始化后方法,不需要为每个bean单独实现BeanPostProcessor
    
        执行顺序BeanPostProcessor>InitializingBean
    
        4： CommandLineRunner和ApplicationRunner在SpringApplication.run()之前，在所有的beans加载完成之后执行，
         * 用于执行一些初始化操作(如加载缓存、读取配置文件、创建线程池等)
         
    4：销毁：     
        
        容器关闭后，如果bean实现了DisposableBean,就会调用接口的destory方法
        也可以通过@PreDestroy实现
    
如何控制spring bean的加载顺序
    
    https://blog.csdn.net/qianshangding0708/article/details/107373538
    
    @Order(value)来配置执行顺序，value是一个int的值，value的值越小越先执行，控制的是执行顺序，不是加载顺序
    
    @DependsOn该注解用于声明当前bean依赖于另外一个bean，被依赖的bean会提前初始化
    
    在@Bean标注的方法上，如果你传入了参数，springboot会自动会为这个参数在spring上下文里寻找这个类型的引用。并先初始化这个类的实例。
    
    @AutoConfigureOrder能改变spring.factories中的@Configuration的顺序。
    
    @AutoConfigureBefore，@AutoConfigureAfter
    
    利用bean生命周期中的扩展点：可以通过实现InstantiationAwareBeanPostProcessor，来实现在实例化某个bean之前提前实例化指定bean
    

    
BeanFactory和ApplicationContext的区别（Bean工厂和应用上下文）
    
    https://blog.csdn.net/qq_20757489/article/details/88543252
    
    1：ApplicationContext是BeanFactory的子类，并且扩展了很多高级特性
    
    1：BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化
    
       而ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean，
       这样，在容器启动时，我们就可以发现Spring中存在的配置错误。
       
                                             
              


FactoryBean 和 BeanFactory 有什么区别？

    BeanFactory 是 Bean 的工厂， ApplicationContext 的父类，IOC 容器的核心，负责生产和管理 Bean 对象。
    
    FactoryBean 是 Bean，可以通过实现 FactoryBean 接口，定制实例化 Bean 的逻辑，通过代理一个Bean对象，对方法前后做一些操作。
    
spring bean加载过程：
    
    

spring bean的实例化过程：
    
    




mybatis:
    
    jdbc连接步骤：
        http://www.itheima.com/news/20200115/174304.html
        https://www.tqwba.com/x_d/jishu/392943.html
        1：加载驱动
        Class.forName("com.mysql.cj.jdbc.Driver");
        
        2：提供jdbc连接的url
         String url="jdbc:mysql://0.0.0.0:3306/xxxx";
         String username="root";
         String password="root";
         
        3：创建数据库连接
        Connection con = DriverManager.getConnection(url,username,password);
        
        4：创建一个statement执行者（PreparedStatement和Statement的区别）
        createStatement()用于创建一个Statement对象来将SQL语句发送到数据库
        prepareStatement(String sql)用于创建一个PreparedStatement对象来将参数化的SQL语句发送到数据库
        
        PreparedStatement是Statement子类，其中Statement只能执行固定的sql语句，而PreparedStatement可以进行动态替换参数
        
        String sql="SELECT * FROM biz_spot WHERE spot_id =? ";
        PreparedStatement statement = con.prepareStatement(sql);
        statement.setLong(1,11L);
        
        5:执行sql语句
        
        ResultSet result = statement.executeQuery();
        
        6：处理返回结果
            while (result.next()){
                System.out.println(result.getString("xxx") + "---" + result.getString("xxx"));
            }
        
        7：关闭JDBC对象
            con.close();
            result.close();
            statement.close();
        
     mybatis连接步骤（底层通过jdbc连接进行数据库操作）
        
        参考：https://blog.csdn.net/u014745069/article/details/80788127和源码
        
        1:SqlSessionFactoryBuilder读取配置文件，包括数据库连接信息，mybaits的配置信息，包扫描等数据来构建一个SqlSessionFactory
        
        2：SqlSessionFactory对象会根据数据库和mybatis配置信息创建一个事务工厂，通过事务工厂创建一个事务，在通过这个事务和设置的执行器类型，生成
        一个Executor执行器，在根据执行器和配置信息生成一个sqlsession
        
        3：然后通过sqlsession 完成和数据库的交互，sqlsession根据mapper中的接口找到对应MappedStatement对象，然后通过Executor
        将MappedStatement对象进行解析，sql参数转化、动态sql拼接，生成jdbc Statement对象，JDBC执行sql，包括事务操作
        
        4：借助MappedStatement中的结果映射关系，将返回结果转化成HashMap、JavaBean等存储结构并返回
               
      mybatis二级缓存
      
--------- redis
   
面试题：
    
    https://bbs.huaweicloud.com/blogs/223176
    
redis数据类型：

        https://gitbook.cn/gitchat/column/5ee1d22c4a99494972797132/topic/5ee1d33f4d9e9b4964d70238
        string：
        list：
        set：
        hash：
        sort set
        hyperloglog
        GEO
        Stream
        
        
        
redis的事务,和mysql有什么不一样
    
    
redis那些地方是单线程的

redis数据淘汰策略：
    
    https://www.cnblogs.com/mysql-hang/articles/10532720.html
    
    1：从设置过期时间的key里面挑选
        1：随机淘汰
        2：淘汰即将过期的
        3：淘汰最近最少使用的
    
    2：所有key中挑选
        1：随机淘汰
        2：淘汰最近最少使用的
        
    3：不淘汰
        内存满了不淘汰任何数据，导致写入操作会报错，读取操作正常使用 默认策略
  
哪些场景用到redis，用到redis中的哪些结构  
    
  
redis分布式锁：

    https://www.jianshu.com/p/47fd7f86c848
    https://www.zhihu.com/question/300767410/answer/1698980571
    
    redis实现分布式锁原理：
    
        加锁：就是在redis里面设置一个key，value（客户端提供唯一的标识）。并且如果存在key就不进行任何操作，设置过期时间（避免死锁）
        
        获取锁：就是一直去尝试向redis中添加一个key，value，如果没有成功等待一段时间再去获取，直到获取到，或者超时
        
        解锁：判断key对应的value和当前存在redis是否一致，一致则删除该key
    
    
    setnx无法指定过期时间，需要在执行完成后执行expire。这样无法保证原子性，可能setnx执行成功了，但是expire没有执行：
    
        解决方案：使用set命令SET lock_key random_value NX PX 5000
                    解释：
                    random_value 是客户端生成的唯一的字符串。
                    NX 代表只在键不存在时，才对键进行设置操作。
                    PX 5000 设置键的过期时间为5000毫秒。

        参考：
            set key value [EX seconds] [PX milliseconds] [NX|XX]
            EX seconds：设置失效时长，单位秒
            PX milliseconds：设置失效时长，单位毫秒
            NX：key不存在时设置value，成功返回OK，失败返回(nil)
            XX：key存在时设置value，成功返回OK，失败返回(nil)
            
            案例：设置name=p7+，失效时长100s，不存在时设置
            1.1.1.1:6379> set name p7+ ex 100 nx
            OK
            1.1.1.1:6379> get name
            "p7+"
            1.1.1.1:6379> ttl name
            (integer) 94
            ————————————————
            版权声明：本文为CSDN博主「p7+」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
            原文链接：https://blog.csdn.net/qq_30038111/article/details/90696233
      
    解决死锁：
        设置锁过期时间
    
    解决锁过期，业务逻辑还没有执行完成：
        加锁时设置一个守护线程，判断锁是否快过期，如果快过期业务逻辑还没有执行完成，就进行续期，重新设置超时时间（redission实现了）
    
    避免释放其他人的锁：
        
        释放锁之前先判断一下redis中的值是否和之前存入的一致。为了保证原子性，用lua脚本来实现查询后删除
        set key value [EX seconds] [PX milliseconds] [NX|XX]
        EX seconds：设置失效时长，单位秒
        PX milliseconds：设置失效时长，单位毫秒
        NX：key不存在时设置value，成功返回OK，失败返回(nil)
        XX：key存在时设置value，成功返回OK，失败返回(nil)
        
        案例：设置name=p7+，失效时长100s，不存在时设置
        1.1.1.1:6379> set name p7+ ex 100 nx
        OK
        1.1.1.1:6379> get name
        "p7+"
        1.1.1.1:6379> ttl name
        (integer) 94
        ————————————————
        版权声明：本文为CSDN博主「p7+」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
        原文链接：https://blog.csdn.net/qq_30038111/article/details/90696233
        
    高可用架构下主节点宕机，没用把set加锁命令同步到从节点，从节点升级为主节点，锁信息丢失
        
        
    实现可重入锁：
       使用Redis的哈希表存储可重入次数，当加锁成功后，使用hset命令，value(重入次数)则是1
       
       解锁时判断可重入次数是否大于0，大于0就减1，为0就删除key
    通过发布订阅方式来同时客户端锁释放，这样客户端就不用一直轮询去获取锁：
        
        当加锁失败后，订阅锁释放的消息，自身进入阻塞状态。
        
        当持有锁的客户端释放锁的时候，发布锁释放的消息。
        
        当进入阻塞等待的其他客户端收到锁释放的消息后，解除阻塞等待状态，再次尝试加锁
                
    setnx方式实现分布式锁：      
        redis通过setnx，或者getnx，set加锁
        get命令去获取锁
        del释放锁
        
        例子：
        SETNX key value，
        功能：
        当且仅当 key 不存在，将 key 的值设为 value ，并返回1；若给定的 key 已经存在，则 SETNX 不做任何动作，并返回0。
        
        GETSET key value
        功能：
        将给定 key 的值设为 value ，并返回 key 的旧值 (old value)，当 key 存在但不是字符串类型时，返回一个错误，当key不存在时，返回nil。
        
        GET key
        功能：
        返回 key 所关联的字符串值，如果 key 不存在那么返回特殊值 nil 。
        
        
        DEL key [KEY …]
        功能：
        删除给定的一个或多个 key ,不存在的 key 会被忽略。
          
  
假如我有2亿的用户,如何去统计在线的人数和具体用户信息

    https://www.zhihu.com/question/433475778/answer/1612399018
    https://www.cnblogs.com/javastack/archive/2021/01/13/14270246.html
    
    bitmap统计1亿用户活跃度需要多少空间：
        bitmap这样一个位图结构的值对象占据多少空间。每一个位是1bit，一亿用户就是一亿bit。8bit=1Byte    
        100000000/8/1024/1024=11.92M
        一天1亿用户也就消耗12M的内存空间。这完全符合要求。1年的话也就4个G
    
    在一台2010MacBook Pro上，offset为2^32-1（分配512MB）需要～300ms，offset为2^30-1(分配128MB)需要～80ms，offset为2^28-1（分配32MB）需要～30ms，offset为2^26-1（分配8MB）需要8ms。<来自官方文档>
    大概的空间占用计算公式是：($offset/8/1024/1024)MB
    
    统计在线人数的方式：
         bitmap（精确统计，内存在可接受范围）或者hyperloglog（存在极低误差，内存占用小）
    
    bitmap设置值：
        SETBIT key 0 1   解释：(0表示位置，1表示存储的值（值要吗是1要吗是0）)
        GETBIT key 1    解释（获取key，位置为1的值）
        BITCOUNT key    解释（统计key中1的数量）
        
        BITOP （AND，OR，NOT，XOR）resutl key1 key2   解释对key1，key2进行与或非，异或操作，结果返回给result
        
    hyperloglog：
        pfadd key "java" "sql"    解释：添加元素 java，sql
        pfcount key               解释：统计key中不重复的元素个数
        pfmerge k3 k k2           解释：将k和ke合并成k3
设计模式

redis hash槽
    
    redis集群，借助槽来实现数据分区，集群有16384个槽
    redis中的每个key都存储在16384个槽中，然后每个槽又被分配到不同的分区上
    
    集群通过，slot=CRC16（key）/16384来计算key属于哪个槽
    
    通过分配槽给不同节点，可以控制控制集群节点的数据量和请求量
    
    从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态
    
redis为什么用hash槽，而不用简单hash和一致性hash
    
    https://www.jianshu.com/p/6ad87a1f070e
    
    简单hash算法：对key进行hash操作，并根据节点数求余。新增节点或这删除节点需要重写进行hash操作。不然会
    出现大量key失效
    
    一致性hash，hash空间是一个圆环，对key进行hash计算后，落到圆环的不同节点，顺时针遇到的第一个节点就是key存储的节点
    相对于简单hash，一致性hash，新增或者删除节点的情况下，需要移动的key相对较少，但是一致性hash容易出现数据倾斜
    
    hash槽，将key通过 CRC16（key）/16384计算后分配到16384不同的槽上，然后把槽分配给各个节点。
    这样key和节点实现了解偶，可以手动指定不同节点的槽数量从而控制节点的请求量和数据量，不会像一致性hash一样出现数据偏移
    
       
    对于槽位的转移和分派，redis 集群是不会自动进行的，而是需要人工配置的。所以 redis 集群的高可用是依赖于节点的主从复制与主从间的自动故障转移

项目中什么地方用到redis，redis宕机了怎么办
    
    rdb，aof快照恢复预热数据，集群主从故障转移。
    
redis是单线程还是多线程，为什么
    
    redis是单进程单线程模式，采用队列模式将并发访问变为串行访问
    
    采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗
    
    Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了


redis并发竞争问题如何解决：
    
     单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，利用setnx实现锁。
   
redis高可用方案：
    
    1 主从：

    2 集群：
        https://www.cnblogs.com/kismetv/p/9853040.html
    3 哨兵：
        https://www.cnblogs.com/kismetv/p/9609938.html
    
    redis单节点：适用于数据可靠性要求不高的纯缓存业务场景。
    

redis 主从复制的过程

    https://zhuanlan.zhihu.com/p/112899242
    https://www.cnblogs.com/daofaziran/p/10978628.html
    https://www.cnblogs.com/kismetv/p/9236731.html
    
    全量同步：
    master服务器会开启一个后台进程用于将redis中的数据生成一个rdb文件，与此同时，服务器会缓存所有接收到的来自客户端的写命令（包含增、删、改），当后台保存进程
    处理完毕后，会将该rdb文件传递给slave服务器，而slave服务器会将rdb文件保存在磁盘并通过读取该文件将数据加载到内存，在此之后master服务器会将在此期间缓存的
    命令通过redis传输协议发送给slave服务器，然后slave服务器将这些命令依次作用于自己本地的数据集上最终达到数据的一致性。
     
    部分同步：
    从redis 2.8版本以前，并不支持部分同步，当主从服务器之间的连接断掉之后，master服务器和slave服务器之间都是进行全量数据同步，但是从redis 2.8开
    始，即使主从连接中途断掉，也不需要进行全量同步，因为从这个版本开始融入了部分同步的概念。部分同步的实现依赖于在master服务器内存中给每个slave服务器维护了
    一份同步日志和同步标识，每个slave服务器在跟master服务器进行同步时都会携带自己的同步标识和上次同步的最后位置。当主从连接断掉之后，slave服务器隔断时间
    （默认1s）主动尝试和master服务器进行连接，如果从服务器携带的偏移量标识还在master服务器上的同步备份日志中，那么就从slave发送的偏移量开始继续上次的同步
    操作，如果slave发送的偏移量已经不再master的同步备份日志中（可能由于主从之间断掉的时间比较长或者在断掉的短暂时间内master服务器接收到大量的写操作），则
    必须进行一次全量更新。在部分同步过程中，master会将本地记录的同步备份日志中记录的指令依次发送给slave服务器从而达到数据一致。
    
    
    自己的回答：
        
        从库发起sync同步，主库调用bgsave全量生成rdb快照，并缓存写命令，完成后发给从库执行。
        当主节点和从节点连接断开又重新连上之后，一般都会进行一个完整的重新同步，但是从Redis2.8开始，支持部分同步。

    
redis 内存满了怎么办

redis的高可用，多主多从怎么通信的

redis持久化,rdb和aof,原理,

    https://blog.csdn.net/qq_45422703/article/details/109747038
    https://segmentfault.com/a/1190000015983518

    rdb：在指定的时间间隔能对你的数据进行快照存储。Redis默认支持的持久化方案。
    
    aof：把所有对redis数据库操作的命令，增删改操作的命令。保存到文件中。数据库恢复时把所有的命令执行一遍即可
    
    
    AOF与RDB的混合模式（redis4.0以后，通过aof-use-rdb-preamble yes开启）
        
        rdb时间间隔内的数据通过aof进行记录。两者结合aof数据恢复慢，rdb数据丢失的情况被很好的解决
  
        允许少量数据丢失选择rdb
rdb在快照过程中怎么解决快照过程中的增量数据
    
    rdb快照过程，生成通过fork生成子进程进行快照生成，父进程继续执行redis读写操作
    
    并且，在快照过程中，redis使用了操作系统提供的写时复制机制，子进程可以共享父进程的内存页，
    有数据变动。父进程会复制一份变动数据给fork子进程写入到rdb快照中  
  
rdb触发时机：
    
    提供了三种机制进行快照存储：
        
        save:
            
            该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成为止
        
        bgsave:
        
            生成通过fork创建子进程异步进行快照存储，完成后自动结束子进程。这样阻塞只会在子进程。
            
            
        自动化：
            
            在redis.conf配置文件里面配置，配置如下：
            
            # 时间策略
            save 900 1
            save 300 10
            save 60 10000
            
            配置解释：
            save 900 1 表示900s内如果有1条是写入命令，就通过bgsave方式产生一次快照，可以理解为就进行一次备份
            save 300 10 表示300s内有10条写入，就通过bgsave方式产生快照
            
            注视掉所有save就可以不进行自动rdb持久化
            
            
          优势：
            1：rdb全量备份
            2：fork生成子进程，不影响主进程
            3：rdb恢复大数据集的速度笔aof快
            
          缺点：快照生成间隔的数据会丢失       
    
     触发时机：
     
        根据我们的 save m n 配置规则自动触发；
        从节点全量复制时，主节点发送rdb文件给从节点完成复制操作，主节点会触发 bgsave；
        执行 debug reload 时；
        执行 shutdown时，如果没有开启aof，也会触发。


aof触发时机：
    
    
rdb执行过程：


aof执行过程：
    
      
缓存穿透，雪崩，击穿：

    https://blog.csdn.net/womenyiqilalala/article/details/105205532
    
    1 穿透：查询一个根本不存在的数据，缓存层和持久层都不会命中。缓存穿透会增加数据库负载
    
    造成原因：业务代码或者数据问题，恶意攻击比如爬虫
    
    解决方案：
        1：持久层没有命中，就set key null。缺点占用缓存空间
        
        2：布隆过滤器：在进入缓存前，先判断key是否存在，如果存在再进入缓存
    
    2 雪崩：大量缓存失效（机器宕机或者大量缓存同时失效），导致大量请求都跑到了存储层。存储层压力过大导致系统崩溃
    
    解决方案：
        
        1：使用集群或者哨兵进行高可用 
        
        2：采用多级缓存，本地进程作为一级缓存，redis作为二级缓存，不同级别的缓存设置的超时时间不同，即使某级缓存过期了，也有其他级别缓存兜底
        缓存的过期时间用随机值，尽量让不同的key的过期时间不同（例如：定时任务新建大批量key，设置的过期时间相同）
        
    3：缓存击穿：
        
        大量请求访问同一个key，此时正好失效。请求落到了持久层，大量线程去重建缓存，会造成后端负载过大
        
        解决方案：
            
            1：互斥锁
                只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可
                
                如果重建缓存时间过长，会导致死锁和线程阻塞情况。
            2：永不过期
                
                存在缓存和数据库中数据不一致情况

布隆过滤器（可以用redis的bitmap实现或者redission，用于判断某个key是否在集合中）

    https://www.cnblogs.com/ysocean/p/12594982.html
    布隆过滤器：一种数据结构，是由一串很长的二进制向量组成，可以将其看成一个二进制数组。既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。
    
    1. 首先需要k个hash函数，每个函数可以把key散列成为1个整数
    2. 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0
    3. 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1
    4. 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。
    
    优点：不需要存储key，节省空间

    缺点：
    1. 算法判断key在集合中时，有一定的概率key其实不在集合中,也就是有一定的识别错误率
    2. 无法删除

12. 简述一下单例模式，项目中有没有用到单例模式
     
    - 饿汉，懒汉线程不安全

    - 在程序运行过程中莫某个类只被实例化一次，只生成一个实例对象，这样可以减少类实例对象的创建和GC压力，提升程序性能
    
    - 线程池
    https://blog.csdn.net/qq_22339269/article/details/90176392


13. @Transactional 怎么保证报错回滚的

    - 和数据库一样，先开启事务，报错时就回滚
    - 使用的是AOP，在程序执行前后添加事务代码



14. 接口和抽象类的区别
    - 单一继承
    - 抽象类有构造器，可以用 `public protected default` 修饰，而接口没有构造器且只能用 public 修饰
    - 接口强调特定功能的实现，而抽象类强调所属关系



jvm

jvm内存空间：
    
    http://www.imooc.com/article/290221
    
    方法区：主要存储静态变量，常量和类信息，即时编译器编译后的代码，java8后用元空间替代，且元空间直接占用的本地内存，而不是堆内存
    
    虚拟机栈：java中的每个线程对应虚拟机栈中的一个线程栈，线程栈时相互独立的，栈中存放了，类局部变量、程序运行状态、方法返回值、方法出口等等，
    每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程
    JVM会为每个线程的虚拟机栈分配一定的内存大小（-Xss参数）
    若单个线程请求的栈深度大于虚拟机允许的深度，则会抛出StackOverflowError（栈溢出错误）。
    
    虚拟机栈的OutOfMemoryError：
    不同于StackOverflowError，OutOfMemoryError指的是当整个虚拟机栈内存耗尽，并且无法再申请到新的内存时抛出的异常。
    JVM未提供设置整个虚拟机栈占用内存的配置参
    
    堆：存储的时对象和数组
    分为老年代，年轻代，其中年轻代分为eden，s0和s1  默认情况老年代占用了1/3的堆内存，年青代占用了2/3 默认情况eden：s0：s1为8：1：1
    
    程序计数器：记录了每个线程执行的字节码位置

jvm参数：

https://www.yuque.com/u21195183/jvm/qpoa81
https://www.processon.com/view/link/5eea141cf346fb1ae56a44e7#map
   
什么对象会进入老年代（回收策略）：
    
    1；根据对象年龄，
        JVM会给对象增加一个年龄（age）的计数器，对象每“熬过”一次GC，年龄就要+1，待对象到达设置的阈值（默认为15岁）就会被移移动到老年代，
        可通过-XX:MaxTenuringThreshold调整这个阈值
     
    2:动态年龄判断：
        在Survivor（s0和s1组成）空间中，相同年龄的一批对象，所占用的内存大于 Survivor的50%，那么大于或者等于这个对象年龄的对象全部进入老年代
    
    3: 大对象直接进入老年代
        
        所谓的大对象就是指，需要大量连续内存空间的java对象，最典型的大对象就是那种很长的字符串及数组。
        虚拟机提供了一个-XX:PretenureSizeThreshold参数，令大于这个设置值得对象直接在老年代中分配
        （这样做的目的是避免在Eden区及两个Survivor之间发生大量的内存拷贝）
      
    4：yongGC后  Survivor区容不下的对象
    
内存分配：
    
    1：对象优先在Eden区分配
    
        大多数情况下，对象在新生代Eden区中分配，当Eden区没有足够的空间进行分配时，虚拟机将发起一次Minor GC；
    虚拟机提供了-XX:PrintGCDetails参数，发生垃圾回收时打印内存回收日志，并且在进程退出时输出当前内存各区域的分配情况。
    
    2：空间分配担保：
        
        在Minor GC前，虚拟机会计算没次晋升到老年代对象的平均大小，判断是否大于老年代的最大可用连续空间。
        如果大于直接进行Full GC
        如果小于，则查看HandlePromotionFailure设置是否允许担保失败。
        如果允许，那将进行Minor GC，（如果Minor GC后存活的对象突增，远远高于平均值，那么将在担保失败后
        进行一次full GC）；
        如果不允许，则改为进行一次Full GC
 
引用类型：

  ![image-20210609215206870](http://img1.sycdn.imooc.com/5d44527900013a0408090390.png)
    
    1：强引用：
        在程序代码中普遍存在，类似Object obj= new Object();只要强引用还在，垃圾回收器永远不会回收引用对象
        
    2：软引用
    3：弱引用
    4；虚引用
                                                    
GC root： 
    
    https://zhuanlan.zhihu.com/p/134575094
    首先我们知道标记算法，JVM
    的标记算法我们可以了解为一个可达性算法，所以所有的可达性算法都会有起点，那么这个起点就是GC Root。
    也就是需要通过GC Root 找出所有活的对象，那么剩下所有的没有标记的对象就是需要回收的对象。
    
GC root特点：
    
    当前时刻存活的对象！

   
哪些可以作为GC root的对象

    虚拟机栈中引用的对象
    方法区中静态属性引用的对象
    方法区中常量引用的对象
    本地方法栈中JNI的引用的对象
    所有被同步锁synchronized持有的对象
    
垃圾回收为什么要停止应用：

    简单回答：可达性分析算法，需要保证分析过程中系统必须保证一致性，也就是对象引用关系在分析过程中不能不断变化。
    
    在gc事件发生过程中，会产生应用的停顿，停顿产生时整个应用程序线程都会被暂停，没有任何响应，有点像卡死的感觉，这个停顿称为STW
    
    可达性分析算法中，枚举根节点(GC ROOT)会导致所有java程序执行线程停顿。
        
        .分析工作必须在一个能确保一致性的快照中进行
        .一致性指整个分析期间整个执行系统像被冻结在某个时间点上
        .如果出现分析过程中对象引用关系还在不断地变化，则分析结果的准确性无法保证。

                                                  
垃圾回收算法：
    
    引用计数法
    　　给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器都为0的对象就是不再被使用的，垃圾收集器将回收该对象使用的内存。
    
    　　优点：
    
    　　　　实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。
    
    　　缺点：
    
    　　　　它需要单独的字段存储计数器，这样的做法增加了存储空间的开销
           每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了时间开销。
           引用计数器有一个严重的问题，即无法处理循环引用的情况。这是一条致命缺陷，导致在Java的垃圾回收器中没有使用这类算法。
           
    可达性分析算法：
        
        自己：以Gcroots为起点，从上往下查询被Gcroots中对象直接或这间接连接的对象，该引用链上的对象都是可达对象也就是存活对象
        那些没有被引用的被标记为垃圾对象。
        
        可达性分析算法是以根对象集合（GCRoots）为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达。
        使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain）
        如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象。
        在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。
        
   ![image-20210609215206870](http://img1.sycdn.imooc.com/5d4452ad0001292c10800344.png)
       
     
    
    标记清除：
       
       https://zhuanlan.zhihu.com/p/51095294
       标记：采用从根集合GC root进行扫描，对存活的对象标记。
       
       清除：清除阶段程序会遍历整个堆，对有标记的对象把标记清除掉等待下次GC，
       对于没有标记的对象则会放到一个单向的空闲列表free_list里面，
       这样当新建对象需要分配内存时我们就可以从free_list里面取出合适的分块
       
      
       优点：
       标记-清除算法不需要进行对象的移动，并且仅对不存活的对象进行处理，在存活对象比较多的情况下极为高效
       
       缺点：
       标记与清除效率低
       在进行GC的时候,需要停止整个应用程序,导致用户体验差
       因为对象不移动，清理出来的空闲内存是不连续的,产生内存碎片。需要维护一个空闲列表。后续可能发生大对象找不到到可利用空间的问题 
    
    复制算法：
    
        https://www.cnblogs.com/zuoxiaolong/p/jvm5.html
        
        将内存非为两成对等两份A,B，新对象存放在A，此时B是空的，进行垃圾回收后，A中存活的对象复制到B，此时A是空的
        然后新对象会放到B，当满足垃圾回收条件并清理完B后，B中存活的对象放到A中，此时B是空的，一直循环下去
        
        优点：解决了标记清除内存碎片的问题
        
        缺点：
        需要额外内存开销，可使用的内存降为原来一半。
        假如大量对象长期无法被回收，那么复制工作花费的时间将无法被忽视。
        所以复制算法适合生命周期短的对象
        
    标记-整理（或标记-压缩算法，Mark-Compact，又或者叫标记清除压缩MarkSweepCompact）：
    
        标记：遍历GC Roots，然后将存活的对象标记
        
        
        整理（压缩）：移动所有存活的对象，且按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收。因此，第二阶段才称为整理阶段。
    
        优点：
            解决来标记清除存在内存碎片的缺点，和复制算法内存50%的而外开销
        
        缺点：
            标记/整理算法唯一的缺点就是效率也不高，不仅要标记所有存活对象，还要整理所有存活对象的引用地址。从效率上来说，标记/整理算法要低于复制算法。
    
    分代回收策略：
        
        不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的回收算法，以便提高回收效率
        
可达性分析算法和标记清除算法的区别：

    可达性分析算法只标记存活对象，标记清除则会标记并清除
            
jvm垃圾回收器：

    通过命令查看垃圾回收策略：java  -XX:+PrintCommandLineFlags  -version
    
   ![image-20210609215206870](http://img1.sycdn.imooc.com/5d4452e30001ee0509720678.png)
   
   
        https://www.cnblogs.com/woniusky/p/11064922.html
       1：垃圾回收器的目的：
            识别和回收垃圾对象进行内存清理，不同代可以使用不同的垃圾回收器：
       
       2：垃圾回收器按照堆内存的分代区分可以分为：（现在普遍的组合Parallel Scavenge和Parallel Old通过-XX:+UseParallelGC指定）
       
             年轻代垃圾回收器：
                Serial（串行限定单核cpu才可以用）基本不会使用串型方式：
                    
                    Serial收集器采用复制算法、串行回收和"stop-the-World"机制的方式执行内存回收。
                    是HotSpot中client模式下的默认新生代垃圾收集器。
                    
                    在单核cpu情况喜爱简单高效
                    
                    在HotSpot虚拟机中，使用-XX:+UseSerialGC参数可以指定年轻代和老年代都使用串行收集器。等价于新生代用Serial GC，且老年代用Serial Old GC

                Parnew（ParNew垃圾收集器是Serial收集器的多线程版本）
                   收集器采用复制算法、bing行回收和"stop-the-World"机制的方式执行内存回收。
                    
                    在程序中，开发人员可以通过选项"-XX:+UseParNewGC"手动指定使用ParNew收集器执行内存回收任务。它表示年轻代使用并行收集器，不影响老年代。
                    
                    -XX:ParallelGCThreads限制线程数量，默认开启和CPU数据相同的线程数
                   
                Parallel Scavenge（并行，java8默认垃圾回收器）
                    
                    收集器采用了复制算法、并行回收和"Stop the World"机制。
                    
                    
                G1（并行）
               
           
            
             老年代垃圾回收器：
                Serial Old（MSC）：
                    Serial Old收集器同样也采用了串行回收和"Stop the World"机制，只不过内存回收算法使用的是标记-压缩算法。
                    是运行在Client模式下默认的老年代的垃圾回收器
                    在Server模式下主要有两个用途：① 与新生代的Parallel scavenge配合使用 ② 作为老年代CMS收集器的后备垃圾收集方案
                    （JDK14中：弃用Parallel Scavenge和Serialold GC组合）
                CMS（并行，并发）：
                    
                    并行垃圾回收：
                    垃圾回收器线程和用户线程并发执行。
                    
                    新生代只能选择ParNew或者Serial收集器中的一个进行搭配使用
                    
                    CMS整个过程比之前的收集器要复杂，整个过程分为4个主要阶段，即初始标记阶段、并发标记阶段、重新标记阶段和并发清除阶段
                    
                    初始标记（Initial-Mark）阶段：在这个阶段中，程序中所有的工作线程都将会因为“Stop-the-World”机制而出现短暂的暂停，这个阶段的主要任务仅仅只是标记出GCRoots能直接关联到的对象。一旦标记完成之后就会恢复之前被暂停的所有应用线程。由于直接关联对象比较小，所以这里的速度非常快。
                    并发标记（Concurrent-Mark）阶段：从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行。
                    重新标记（Remark）阶段：由于在并发标记阶段中，程序的工作线程会和垃圾收集线程同时运行或者交叉运行，因此为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短。
                    并发清除（Concurrent-Sweep）阶段：此阶段清理删除掉标记阶段判断的已经死亡的对象，释放内存空间。由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的
                    
                    尽管CMS收集器采用的是并发回收（非独占式），但是在其初始化标记和再次标记这两个阶段中仍然需要执行“Stop-the-World”机制暂停程序中的工作线程，不过暂停时间并不会太长，因此可以说明目前所有的垃圾收集器都做不到完全不需要“stop-the-World”，只是尽可能地缩短暂停时间。
                    
                    由于最耗费时间的并发标记与并发清除阶段都不需要暂停工作，所以整体的回收是低停顿的
                    
                    另外，由于在垃圾收集阶段用户线程没有中断，所以在CMS回收过程中，还应该确保应用程序用户线程有足够的内存可用。
                    因此，CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，
                    而是当堆内存使用率达到某一阈值时，便开始进行回收，以确保应用程序在CMS工作过程中依然有足够的空间支持应用程序运行。
                    要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure” 失败，
                    这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了
                 
                    CMS收集器的垃圾收集算法采用的是标记清除算法，这意味着每次执行完内存回收后，
                    由于被执行内存回收的无用对象所占用的内存空间极有可能是不连续的一些内存块，不可避免地将会产生一些内存碎片。
                    那么CMS在为新对象分配内存空间时，
                    将无法使用指针碰撞（Bump the Pointer）技术，而只能够选择空闲列表（Free List）执行内存分配。
                    
                     CMS的优点
                    
                    并发收集
                    低延迟
                    
                    13.6.2. CMS的弊端
                    
                    会产生内存碎片，导致并发清除后，用户线程可用的空间不足。在无法分配大对象的情况下，不得不提前触发FullGC。
                    CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。
                    CMS收集器无法处理浮动垃圾。可能出现“Concurrent Mode Failure"失败而导致另一次Full GC的产生。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的，那么在并发标记阶段如果产生新的垃圾对象，CMS将无法对这些垃圾对象进行标记，最终会导致这些新产生的垃圾对象没有被及时回收，从而只能在下一次执行GC时释放这些之前未被回收的内存空间。

                Parallel Old（并行回收器）：
                    Parallel Old收集器采用了标记-压缩算法，并行回收和"Stop-the-World"机制
               
                G1（并行）
             
独占式

    使用了“Stop-the-World”机制，也就是垃圾回收过程会暂停其他所有应用线程。            

由于ParNew收集器是基于并行回收，那么是否可以断定ParNew收集器的回收效率在任何场景下都会比serial收集器更高效？

    ParNew 收集器运行在多CPU的环境下，由于可以充分利用多CPU、多核心等物理硬件资源优势，可以更快速地完成垃圾收集，提升程序的吞吐量。
    但是在单个CPU的环境下，ParNew收集器不比Serial 收集器更高效。虽然Serial收集器是基于串行回收，但是由于CPU不需要频繁地做任务切换，因此可以有效避免多线程交互过程中产生的一些额外开销。                
    
Parallel Scavenge和Parnew对比：

    都是年轻代垃圾回收
    都采用复制算法、并行回收和"Stop the World"机制
    
    区别：Parallel Scavenge只要是为了达到一个可控制的吞吐量（Throughput），它也被称为吞吐量优先的垃圾收集器。
    主要适合在后台运算而不需要太多交互的任务
    
G1和CMS的区别 
    

分代思想说一下垃圾回收

    介绍一下什么是分代：
        将不同生命周期的对象进行分区管理
        
    分代的好处：
         不同生命周期的对象采取不同的收集方式，可以提高回收效率。比如年轻代用复制算法，老年代使用使用标记清除或标记整理算法
    垃圾回收中的分代案例：
        
       年青代中的gc
    
为什么分代：
   
    不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。

年青代中的gc
    
    年轻代大小（PSYoungGen total 9216K）=eden大小（eden space 8192K）+1个survivor大小（from space 1024K）
   
    年轻代由于其对象存活时间短，且需要经常gc，因此采用效率较高的复制算法
    年青代分为三个部分：1个Eden区和2个Survivor区（s0，s1）。默认比例是8：1：1 
    GC开始的时候，对象只存在Eden区和from区，经过GC后Eden区中仍然存活的对象，被移动到to区，from区中达到年龄阀值（默认为15岁可通过-XX:MaxTenuringThreshold调整）的
    被移动到老年区还有一种情况相同年龄的一批对象，所占用的内存大于 Survivor（s0或者s1的内存，因为复制算法，s0和s1有一个一定是空的）的50%，那么大于或者等于这个对象年龄的对象也会进入老年代
    ，没有进入老年代的被移动到to区，此时Eden和from区被清空，然后from和to会交换角色，下一次GC之前的to区
    变成了from区。永远保证to区是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中
    老年代和永久代因为其存活对象时间长，因此使用标记清除或标记整理算法
 
 
    
 
GC执行机制：
    
    分为两种
    
    Scavenge GC(Minor GC)：
    
    
    Full GC：
    
    
什么情况会触发垃圾回收  
    
   ![image-20210609215206870](http://img1.sycdn.imooc.com/5d44537c0001855109180611.png)
    Full GC触发场景
        
        调用System.gc时，系统建议执行Full GC，但是不必然执行
        老年代空间不足
        方法区空间不足
        通过Minor GC后进入老年代的平均大小大于老年代的剩余空间
        堆中分配很大的对象，而老年代没有足够的空间
    Young GC触发场景
    
   ![image-20210609215206870]( http://img1.sycdn.imooc.com/5d44538d00011b3910580237.png)
        当Eden区满时,触发Minor GC.

    
finalize作用：

    允许开发人员提供对象被销毁之前的自定义处理逻辑
        
    Java技术使用finalize()方法，来实现对象被清理前做些逻辑操作。
    
    这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象调用的。
    
    它是在Object类中定义的，因此所有的类都继承了它。
    
    子类覆盖finalize()方法以整理系统资源或者执行其他清理工作。比如关闭io流，数据库连接等

是否可以手动调用finalize()方法：

    永远不要主动调用某个对象的finalize()方法I应该交给垃圾回收机制调用：
        在finalize()时可能会导致对象复活。
        finalize()方法的执行时间是没有保障的，它完全由GC线程决定，极端情况下，若不发生GC，则finalize()方法将没有执行机会。
        一个糟糕的finalize()会严重影响Gc的性能。
        
        
        
    
为什么老年代使用标记压缩、新生代使用复制算法

    新生代都是一些生命周期短的对象，且频繁发生GC，需要效率高一点的垃圾回收算法。
    老年代都是一些存活周期比较长的对象，用复制算法首先需要一倍的空间消耗，而且长期存活的对象进行来回复制,影响性能。
    
如果年轻代经常发生gc，会是什么原因，如何解决


项目上发生oom如何定位问题
    
    通过日志判断是元空间还是永久代(方法区)或者是堆内存，或者是虚拟机栈内存溢出，                     
       
       


如何调整新老年代的空间，项目上怎么设计的，你们生产的比例一般是多少


年青代经常gc,可以调高年轻代的空间么，这样做的优缺点。


gc工具


g1垃圾回收器的回收流程




---





1. java中有那些锁

 
3. HashMap的底层结构和安全性


4. 线程池的一些参数
   - 核心线程数，最大线程数，非核心线程数的存活时间及单位
   - 阻塞队列
   - 线程工厂
   - 拒绝策略：报错，直接丢弃，丢弃队列种第一个并执行，使用当前线程运行，自定义 `RejectedExecutionHandler`





---



1. mybatis相关

2. jvm/jvm的内存模型，一个对象是怎么加载的，对象里的静态变量和非静态变量放那里
   - 静态变量放在堆中，非静态变量放在栈




6. Spring refresh源码





---



1. 项目中做了哪个模块，主要做什么，遇到的难题怎么解决的，系统还有什么不太好的，有没有优化的办法
2. Mybatis如何映射双主键
3. SQL调优
4. HashMap的底层结构，扩容是怎么实现的
5. Mysql事务隔离事务隔离级别
6. Mysql如何看一条sql是否被优化了
7. Spring用到了哪些设计模式
8. SpringMVC执行流程
9. 如何解决死锁
10. 有没有遇到过内存溢出，如何解决
    - OutOfMemoryError 
    - StackOverflowError
    - jvm 优化





---



1. 微服务服务间通信
   - 远程过程调用，RPC，RestTemplate，Ribbon，Fegin
   - 消息队列
   
2. eureka和zk的区别
   - Zookeeper 保证的是CP, Eureka 则是AP
   - Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务
   - Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障
   
3. 服务降级,服务熔断

4. mybatis 如何返回主键

5. 消息中间件,如何保证消息的顺序

6. 队列的定义方式

      
8. arrylist为什么查询快

   - `ArrayList` 是连续存放元素的，找到第一个元素的首地址，再加上每个元素的占据的字节大小就能定位到对应的元素
   - `LinkList` 执行插入删除操作时，只需要操作引用即可，元素不需要移动元素，但分布在内存的不同地方，通过引用来互相关联，故查找效率低

9. arrylist和linklist的区别

10. linklist 操作数据

11. 乐观锁悲观锁

    - 悲观锁，默认数据是被锁的，需求获取锁后才能执行，如 `Synchronized` 和 `ReentrantLock` ，关系型数据库中的行锁，表锁，数据库的悲观锁实现往往依靠数据库本身的锁功能实现。
        select for update 查询后加锁https://www.cnblogs.com/wxgblogs/p/6849064.html

    - 乐观锁在进行写入操作的时候会判断当前数据是否被修改过，常见的实现方案有`版本号机制` 和 `CAS实现` ，乐观锁多适用于多读的应用类型，这样可以提高吞吐量，`java.util.concurrent.atomic` 下的原子类就是使用CAS实现的

      

12. 微服务怎么注册的

    - 

13. 服务间调用fegin的原理







https://www.jetbrains.com/idea/download/other.html

---



1. 项目上负责哪些模块

2. 在你的项目种如何排查出错的是那个微服务

3. 分布式锁解决方案

4. 分布式事务

限流
    
    
    
    
8. 简述一下 synchronized

   - `synchronized` 是一种同步锁，可以修饰代码块，成员变量，方法
   - 修饰代码块时，需指定加锁的对象，对给定对象加锁，进入同步代码块之前要先获取给定对象的锁
   - 若修饰的是普通方法，作用的对象是当前对象加锁，也称为对象锁，多个线程访问同一个对象是同步的，访问不同对象是不同步的
   - 若修饰的是静态方法，则锁住的就是当前类，称为类锁，无论是多个线程访问一个还是多个对象都是同步的

9. synchronized 和 ReentrantLock

   - `ReentrantLock` 可以完成 `synchronized`  的所有功能
   - `ReentrantLock` 有更灵活的方法，公平锁
   - `ReentrantLock` 不会自动释放锁，必须要现实的释放
   - `ReentrantLock`  的 `tryLock`  方法可以以非阻塞的方式获取锁
   - 

10. 乐观锁和悲观锁

11. 线程池的几个重要参数

    - 核心线程数
    - 最大线程数
    - 最大线程数的存活时间及单位
    - 线程工厂
    - 阻塞队列
    - 拒绝策略

12. 如何停止线程池

    - `shtudown`：平缓的结束线程，若任务还没执行完，线程池并不会立即停止工作，而是等待线程池中的任务都执行完成后才会`shutdown`掉，但是如果执行`shutdown`了，外界还在继续提交任务到线程池，那么线程池会直接采取拒绝策略

    - `shutdownNow`：暴力结束线程池，他的返回值是队列里未被执行的任务

    - `isShutdown`：判断线程是否已经`shutdown`

    - shutdownNow和shuwdown调用完，线程池并不是立马就关闭了，要想等待线程池关闭，还需调用awaitTermination方法来阻塞等待

      

13. 有6个线程，如何保证前面5个线程执行完之后，第6个线程最后执行

    - `join` 方法

      ```java
      t1.start();
      t1.join();
      
      t2.start();
      t2.join();
      ```

      

    - 使用 `Executors.newSingleThreadExecutor()` ，调用 `submit` 方法，会把线程放在一个FIFO队列，依次执行线程

    - `java.util.concurrent.CountDownLatch` 

    - `java.util.concurrent.CompletableFuture`

14. Java 中的原子类，还问了什么aba的问题，不太记得了

15. Java中的ThreadPoolExecutor，说一下Executor的几个线程池

16. 线程池有哪几种拒绝策略

17. 为什么要使用线程池，一般怎么设置线程池的数量



19. 单例模式有哪几种，double check 的懒汉式下为什么使用 volatile

20. 简述一下spring

21. spirng中用到了哪几种设计模式

22. jdk动态代理和cglib动态代理的区别，默认使用哪种

23. spring / mysql 事务了解吗

24. spring / mysql 的事务隔离级别

25. spring @Transactional 和 aop 的关系

26. 简述一下spring bean 的生命周期

27. @Autowired 和 @Resource 的区别

28. 如何保证 bean 的加载顺序，比如说有A B两个对象，如何先加载A然后在加载B
    AutoConfigureBefore

29. mysql 有多少种索引，他们之间的联系和区别，然后出了一道题判断哪条语句走了索引

30. 索引的数据结构，为什么使用B+不用其他

31. mysql innodb 和 myisam 的区别

32. select会加锁吗，update呢，加什么锁

33. 行锁和表锁

34. mysql的一个重要问题，不记得了，很重要，但是我没看过



41. new String("") 和 String = "a" ，这两个会存在jvm中的那个地方

42. 双亲派委

43. jdk各版本的内存结构

44. <font color='red'>垃圾回收机制</font>

    
题目：
    https://blog.csdn.net/sufu1065/article/details/88051083





6.jvm 结构,程序计数器来干嘛的,jvm新生代在gc多少次后到老年代
8,jvm的1.8的垃圾回收器是什么

mysql索引怎么实现的,为什么要这样
10.一个字段是vchar的很长,我怎么加索引?

https://blog.csdn.net/sinat_37903468/article/details/104610975


多线程自问：
https://segmentfault.com/a/1190000013813740


百度面试问题：
https://www.nowcoder.com/discuss/473778?channel=-2&source_id=discuss_terminal_discuss_sim
华为
https://www.nowcoder.com/discuss/673973?source_id=discuss_experience_nctrack&channel=-1

百度--只有自己知道有多难，我命由我不由天
https://www.nowcoder.com/discuss/406629?source_id=discuss_experience_nctrack&channel=-1
https://www.nowcoder.com/discuss/667468?source_id=discuss_experience_nctrack&channel=-1
https://www.nowcoder.com/discuss/664951?source_id=discuss_experience_nctrack&channel=-1
https://www.nowcoder.com/discuss/664953?source_id=discuss_experience_nctrack&channel=-1
https://www.nowcoder.com/discuss/409450?source_id=discuss_experience_nctrack&channel=-1
https://www.nowcoder.com/discuss/584725?source_id=discuss_experience_nctrack&channel=-1

自行查找答案
https://blog.csdn.net/m0_46995061/article/details/110953211

https://blog.csdn.net/weixin_44152379/article/details/112399155


还有一个,就是单例模式,然后解决反射,clone,和反序列化创建单例的问题



大量数据导出到excl：
    一种解决方案：使用csv格式导出，分页查询数据，倒入到csv，如果没有顺序要求可以用异步。尽量不要时时下载，让前端长时间等待后端返回结果
    让后端生成文件后存储到文件服务器，发消息给用户，用户手动下载。







泛型中extends和super的区别



微服务注册中心的理解

cap的概念和场景，以及为什么不能全都要


1.sql的优化问题
2.nginx的代理，什么是正向代理，反向代理
3.mybatis-plus相关的使用
4.Docker如何部署一个原始的代码
5.请求出问题如何快速定位，抓包(不懂)
6.Docker如何确定那个实例资源占用高
7.nginx的负载均衡策略
8.redis的淘汰策略，redis的常用数据结构



















































































